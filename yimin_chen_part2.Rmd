---
title: "P8106_yiminchen_secondaryanalysis" 
author: "Yimin Chen (yc4195), Yang Yi (yy3307), Qingyue Zhuo (qz2493)"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


```{r, echo = T, message = FALSE, results='hide', warning=FALSE,include = FALSE}
library(caret)
library(MASS)
library(mlbench)
library(pROC)
library(klaR)
library(tidyverse)
library(corrplot)
library(leaps)
library(glmnet)
library(earth)
library(AppliedPredictiveModeling)
library(rpart.plot)
library(vip)
library(ISLR)
library(e1071)
library(kernlab)
```
## Import and data manipulation

```{r, results='hide'}
# Load recovery.RData environment
load("./recovery.Rdata")

dat %>% na.omit()

# dat1 draw a random sample of 2000 participants Uni:3307
set.seed(3307)

dat1 = dat[sample(1:10000, 2000),]

dat1 = 
  dat1[, -1] %>% 
  mutate(
    recovery_time = as.factor(
      case_when(recovery_time <= 30 ~ "long", recovery_time > 30 ~ "short")
    ),
    gender = as.factor(gender),
    race = as.factor(race),
    smoking = as.factor(smoking),
    hypertension = as.factor(hypertension),
    diabetes = as.factor(diabetes),
    vaccine = as.factor(vaccine),
    severity = as.factor(severity),
    study = as.factor(
      case_when(study == "A" ~ 1, study == "B" ~ 2, study == "C" ~ 3)
      )
    )

# dat2 draw a random sample of 2000 participants Uni:2493
set.seed(2493)

dat2 = dat[sample(1:10000, 2000),]

dat2 = 
  dat2[, -1] %>% 
  mutate(
    recovery_time = as.factor(
      case_when(recovery_time <= 30 ~ "long", recovery_time > 30 ~ "short")
    ),
    gender = as.factor(gender),
    race = as.factor(race),
    smoking = as.factor(smoking),
    hypertension = as.factor(hypertension),
    diabetes = as.factor(diabetes),
    vaccine = as.factor(vaccine),
    severity = as.factor(severity),
    study = as.factor(
      case_when(study == "A" ~ 1, study == "B" ~ 2, study == "C" ~ 3)
      )
    )

# Merged dataset with unique observation
covid_dat = rbind(dat1, dat2) %>% 
  unique()

covid_dat2 = model.matrix(recovery_time ~ ., covid_dat)[, -1] #ignore intercept


# Partition dataset into two parts: training data (70%) and test data (30%)
rowTrain = createDataPartition(y = covid_dat$recovery_time, p = 0.7, list = FALSE)

trainData = covid_dat[rowTrain, ]
testData = covid_dat[-rowTrain, ]

# matrix of predictors
x1 = covid_dat2[rowTrain,]
# vector of response
y1 = covid_dat$recovery_time[rowTrain]
# matrix of predictors
x2 = covid_dat2[-rowTrain,]
# vector of response
y2 = covid_dat$recovery_time[-rowTrain]

ctrl1 = trainControl(method = "repeatedcv", number = 10, repeats = 5)
ctrl2 = trainControl(method = "cv",
                          classProbs = TRUE,
                          summaryFunction = twoClassSummary)
```

## Data visualization

## Model training

classification 

- glm + penalized logistice regreesion L8
- GAM  L8
- MARS  L8
- QDA  L9
- LDA  L9
- Navie Bayes  L9
- classification tree: L11
- random forest L12
- boosting L12
- support vecotr machines L13

# Logistic regression and its cousins

## GLM


```{r}

set.seed(2)
model.glm <- train(x = covid_dat2[rowTrain,],
                   y = covid_dat$recovery_time[rowTrain],
                   method = "glm",
                   metric = "ROC",
                   trControl = ctrl2)
```

## Penalized logistic regression

Penalized logistic regression can be fitted using `glmnet`. We use the `train` function to select the optimal tuning parameters.

```{r}
glmnGrid <- expand.grid(.alpha = seq(0, 1, length = 21),
                        .lambda = exp(seq(-8, -1, length = 50)))
set.seed(2)
model.glmn <- train(x = covid_dat2[rowTrain,],
                   y = covid_dat$recovery_time[rowTrain],
                    method = "glmnet",
                    tuneGrid = glmnGrid,
                    metric = "ROC",
                    trControl = ctrl2)

model.glmn$bestTune

myCol<- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
              superpose.line = list(col = myCol))

plot(model.glmn, par.settings = myPar, xTrans = function(x) log(x))
```

## GAM

```{r}
set.seed(2)
model.gam <- train(x = covid_dat2[rowTrain,],
                   y = covid_dat$recovery_time[rowTrain],
                   method = "gam",
                   metric = "ROC",
                   trControl = ctrl2)


model.gam$finalModel

plot(model.gam$finalModel, select = 3)
```


## MARS

```{r}
set.seed(2)
model.mars <- train(x = covid_dat2[rowTrain,],
                   y = covid_dat$recovery_time[rowTrain],
                    method = "earth",
                    tuneGrid = expand.grid(degree = 1:4, 
                                           nprune = 2:20),
                    metric = "ROC",
                    trControl = ctrl2)

plot(model.mars)

coef(model.mars$finalModel) 

vip(model.mars$finalModel)
```


```{r}
res <- resamples(list(GLM = model.glm, 
                      GLMNET = model.glmn, 
                      GAM = model.gam,
                      MARS = model.mars))
summary(res)

bwplot(res, metric = "ROC")
```

## test data performance for Logistic regression and its cousins
```{r, warning=FALSE}
glm.pred <- predict(model.glm, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]
glmn.pred <- predict(model.glmn, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]
gam.pred <- predict(model.gam, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]
mars.pred <- predict(model.mars, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]

roc.glm <- roc(covid_dat$recovery_time[-rowTrain], glm.pred)
roc.glmn <- roc(covid_dat$recovery_time[-rowTrain], glmn.pred)
roc.gam <- roc(covid_dat$recovery_time[-rowTrain], gam.pred)
roc.mars <- roc(covid_dat$recovery_time[-rowTrain], mars.pred)

auc <- c(roc.glm$auc[1], roc.glmn$auc[1], 
         roc.gam$auc[1], roc.mars$auc[1])

modelNames <- c("glm","glmn","gam","mars")

ggroc(list(roc.glm, roc.glmn, roc.gam, roc.mars), legacy.axes = TRUE) + 
  scale_color_discrete(labels = paste0(modelNames, " (", round(auc,3),")"),
                       name = "Models (AUC)") +
  geom_abline(intercept = 0, slope = 1, color = "grey")

```

# Discriminant Analysis

## LDA
```{r,warning=FALSE}
set.seed(2)

model.lda <- train(x = covid_dat2[rowTrain,],
                   y = covid_dat$recovery_time[rowTrain],
                   method = "lda",
                   metric = "ROC",
                   trControl = ctrl2)
```

## QDA

```{r,warning=FALSE}
set.seed(2)
model.qda <- train(x = covid_dat2[rowTrain,],
                   y = covid_dat$recovery_time[rowTrain],
                   method = "qda",
                   metric = "ROC",
                   trControl = ctrl2)
```

## Naive Bayes (NB)

There is one practical issue with the NB classifier when nonparametric estimators are used. When a new data point includes a feature value that never occurs for some response class, the posterior probability can become zero. To avoid this, we increase the count of the value with a zero occurrence to a small value, so that the overall probability doesn't become zero. In practice, a value of one or two is a common choice. 
This correction is called "Laplace Correction," and is implemented via the parameter `fL`. The parameter `adjust` adjusts the bandwidths of the kernel density estimates, and a larger value means a more flexible estimate.

```{r, warning=FALSE,warning=FALSE}
nbGrid <- expand.grid(usekernel = c(FALSE,TRUE),
                      fL = 1, 
                      adjust = seq(.2, 3, by = .2))

set.seed(2)
model.nb <- train(x = covid_dat2[rowTrain,],
                  y = covid_dat$recovery_time[rowTrain],
                  method = "nb",
                  tuneGrid = nbGrid,
                  metric = "ROC",
                  trControl = ctrl2)

plot(model.nb)
```

```{r,warning=FALSE}
res <- resamples(list(LDA = model.lda, QDA = model.qda, NB = model.nb))
summary(res)
```

## test set performance for Discriminant Analysis
```{r,warning=FALSE}
lda.pred <- predict(model.lda, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]
nb.pred <- predict(model.nb, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]
qda.pred <- predict(model.qda, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]


roc.lda <- roc(covid_dat$recovery_time[-rowTrain], lda.pred)
roc.nb <- roc(covid_dat$recovery_time[-rowTrain], nb.pred)
roc.qda <- roc(covid_dat$recovery_time[-rowTrain], qda.pred)


auc <- c(roc.lda$auc[1], roc.qda$auc[1], roc.nb$auc[1])

plot(roc.lda, legacy.axes = TRUE)
plot(roc.qda, col = 2, add = TRUE)
plot(roc.nb, col = 3, add = TRUE)

modelNames <- c("lda","qda","nb")
legend("bottomright", legend = paste0(modelNames, ": ", round(auc,3)),
       col = 1:3, lwd = 2)
```

# classification tree models


## rpart

```{r,warning=FALSE}


set.seed(2)

model.rpart = train(recovery_time ~ .,
                  covid_dat,
                  subset = rowTrain,
                  method = "rpart",
                  tuneGrid = data.frame(cp = exp(seq(-6, -3, len = 50))),
                  trControl = ctrl2,
                  metric = "ROC")

ggplot(model.rpart, highlight = TRUE)

rpart.plot(model.rpart$finalModel)

```

## ctree

```{r,warning=FALSE}

set.seed(2)


model.ctree = train(recovery_time ~ .,
                  covid_dat,
                  subset = rowTrain,
                  method = "ctree",
                  tuneGrid = data.frame(mincriterion = 1 - exp(seq(-2, -1, length = 50))),
                  metric = "ROC",
                  trControl = ctrl2)

ggplot(model.ctree, highlight = TRUE)

plot(model.ctree$finalModel)
```

## test set performance for classification tree models

```{r,warning=FALSE}
resamp_tree <- resamples(list(rpart = model.rpart, 
                         ctree = model.ctree))
summary(resamp_tree)
```



## Support Vector Machines
```{r,warning=FALSE}
set.seed(2)
# kernal linear
model.svml = tune.svm(recovery_time ~ .,
                      data = covid_dat[rowTrain, ],
                      kernel = "linear",
                      cost = exp(seq(-5, 2, len = 50)),
                      scale = TRUE)

plot(model.svml)
#best.parameters
model.svml$best.parameters
best_linear_svc=model.svml$best.model
summary(model.svml)

#test error
linear_test_preds = predict(best_linear_svc, newdata = covid_dat[-rowTrain, ])
confusionMatrix(data = linear_test_preds, 
                reference = covid_dat$recovery_time[-rowTrain])

```

```{r,warning=FALSE}

#radial kernel
set.seed(2)

model.svmr = tune.svm(recovery_time ~ .,
                      data = covid_dat[rowTrain, ],
                      kernel = "radial",
                      cost = exp(seq(-3, 8, len = 50)),
                      gamma = exp(seq(-10, 4, len = 20)),
                      scale = TRUE)

plot(model.svmr, transform.y = log, transform.x = log, color.palette = terrain.colors)
best_radial = model.svmr$best.parameters
best_radial
best_radial_svm = model.svmr$best.model
summary(best_radial_svm)

# test
radial_test_preds = predict(best_radial_svm, newdata = covid_dat[-rowTrain, ])
confusionMatrix(data = radial_test_preds, reference = covid_dat$recovery_time[-rowTrain])

```

###  test data performance of SVM methods

```{r,warning=FALSE}
resamp <- resamples(list(svml = model.svml, 
                         svmr = model.svmr, 
                        ))
bwplot(resamp)
```


```{r,warning=FALSE}
pred.svml <- predict(model.svml, newdata = covid_dat2[-rowTrain,])
pred.svmr <- predict(model.svmr, newdata = covid_dat2[-rowTrain,])

confusionMatrix(data = pred.svml, 
                reference = covid_dat$recovery_time[-rowTrain])

confusionMatrix(data = pred.svmr, 
                reference = covid_dat$recovery_time[-rowTrain])
```


```{r resample, cache=TRUE,warning=FALSE}
res <- resamples(list(GLM = model.glm, GLMNET = model.glmn, GAM = model.gam, MARS = model.mars, CTREE = model.ctree, RPART = model.rpart, LDA = model.lda, QDA = model.qda, NB = model.nb,SVML=model.svml,SVMR=model.svmr))
trainROC <- bwplot(res, metric = "ROC")
summary(res)
```


```{r, warning=FALSE}

#pred
glm.pred <- predict(model.glm, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]
glmn.pred <- predict(model.glmn, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]
gam.pred <- predict(model.gam, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]
mars.pred <- predict(model.mars, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]

ctree.pred <- predict(model.ctree, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]
rpart.pred <- predict(model.rpart, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]

lda.pred <- predict(model.lda, newdata =covid_dat2[-rowTrain,], type = "prob")[,2]
qda.pred <- predict(model.qda, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]
nb.pred <- predict(model.nb, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]

svml.pred <- predict(model.svml, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]
svmr.pred <- predict(model.svmr, newdata = covid_dat2[-rowTrain,], type = "prob")[,2]

#roc
roc.glm <- roc(covid_dat$recovery_time[-rowTrain], glm.pred)
roc.glmn <- roc(covid_dat$recovery_time[-rowTrain], glmn.pred)
roc.gam <- roc(covid_dat$recovery_time[-rowTrain], gam.pred)
roc.mars <- roc(covid_dat$recovery_time[-rowTrain], mars.pred)

roc.ctree <- roc(covid_dat$recovery_time[-rowTrain], ctree.pred)
roc.rpart <- roc(covid_dat$recovery_time[-rowTrain], rpart.pred)

roc.lda <- roc(covid_dat$recovery_time[-rowTrain], lda.pred)
roc.qda <- roc(covid_dat$recovery_time[-rowTrain], qda.pred)
roc.nb <- roc(covid_dat$recovery_time[-rowTrain], nb.pred)

roc.svml <- roc(covid_dat$recovery_time[-rowTrain], svml.pred)
roc.svmr <- roc(covid_dat$recovery_time[-rowTrain], svmr.pred)


auc <- c(roc.glm$auc[1], roc.glmn$auc[1], 
         roc.gam$auc[1], roc.mars$auc[1], 
         roc.lda$auc[1],roc.qda$auc[1], roc.nb$auc[1],
         roc.ctree$auc[1], roc.rpart$auc[1], 
         roc.svml$auc[1], roc.svmr$auc[1]
         )

plot(roc.glm, legacy.axes = TRUE)
plot(roc.glmn, col = 2, add = TRUE)

plot(roc.gam, col = 3, add = TRUE)
plot(roc.mars, col = 4, add = TRUE)

plot(roc.lda, col = 5, add = TRUE)
plot(roc.qda, col = 6, add = TRUE)
plot(roc.nb, col = 7, add = TRUE)

plot(roc.ctree, col = 8, add = TRUE)
plot(roc.rpart, col = 9, add = TRUE)

plot(roc.svml, col = 10, add = TRUE)
plot(roc.svmr, col = 11, add = TRUE)


modelNames <- c("glm","glmn","gam","mars","lda","qda","nb", "ctree",  "rpart","svm (linear kernel)", "svm (radial kernel)")
legend("bottomright", legend = paste0(modelNames, ": ", round(auc,3)),
       col = 1:11, lwd = 2)
```
