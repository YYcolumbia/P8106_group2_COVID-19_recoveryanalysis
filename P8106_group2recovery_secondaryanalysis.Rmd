---
title: "P8106_group2recovery_secondaryanalysis" 
author: "Yimin Chen (yc4195), Yang Yi (yy3307), Qingyue Zhuo (qz2493)"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


```{r, echo = T, message = FALSE, results='hide', warning=FALSE,include = FALSE}
library(caret)
library(MASS)
library(mlbench)
library(pROC)
library(klaR)
library(tidyverse)
library(corrplot)
library(leaps)
library(glmnet)
library(earth)
library(AppliedPredictiveModeling)
library(rpart.plot)
library(vip)
library(ISLR)
library(e1071)
library(kernlab)
library(ggplot2)
library(parallel)
library(doParallel)


theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Import and data manipulation

```{r, results='hide'}
# Load recovery.RData environment

load('./recovery.Rdata')

dat %>% na.omit()

# dat1 draw a random sample of 2000 participants Uni:3307
set.seed(3307)

dat1 = dat[sample(1:10000, 2000),]

dat1 = 
  dat1[, -1] %>% 
  mutate(
    recovery_time = as.factor(
      case_when(recovery_time <= 30 ~ "long", recovery_time > 30 ~ "short")
    ),
    gender = as.factor(gender),
    race = as.factor(race),
    smoking = as.factor(smoking),
    hypertension = as.factor(hypertension),
    diabetes = as.factor(diabetes),
    vaccine = as.factor(vaccine),
    severity = as.factor(severity),
    study = as.factor(
      case_when(study == "A" ~ 1, study == "B" ~ 2, study == "C" ~ 3)
      )
    )

# dat2 draw a random sample of 2000 participants Uni:2493
set.seed(2493)

dat2 = dat[sample(1:10000, 2000),]

dat2 = 
  dat2[, -1] %>% 
  mutate(
    recovery_time = as.factor(
      case_when(recovery_time <= 30 ~ "long", recovery_time > 30 ~ "short")
    ),
    gender = as.factor(gender),
    race = as.factor(race),
    smoking = as.factor(smoking),
    hypertension = as.factor(hypertension),
    diabetes = as.factor(diabetes),
    vaccine = as.factor(vaccine),
    severity = as.factor(severity),
    study = as.factor(
      case_when(study == "A" ~ 1, study == "B" ~ 2, study == "C" ~ 3)
      )
    )

# Merged dataset with unique observation
covid_dat = rbind(dat1, dat2) %>% 
  unique()

covid_dat2 = model.matrix(recovery_time ~ ., covid_dat)[, -1]

# Partition dataset into two parts: training data (70%) and test data (30%)
rowTrain = createDataPartition(y = covid_dat$recovery_time, p = 0.7, list = FALSE)

trainData = covid_dat[rowTrain, ]
testData = covid_dat[-rowTrain, ]

ctrl = trainControl(method = "cv", number = 10)
ctrl1 = trainControl(method = "repeatedcv", number = 10, repeats = 5)
ctrl2 = trainControl(method = "cv",
                          classProbs = TRUE,
                          summaryFunction = twoClassSummary)
```

# 1. Data visualization

## 1.1 Correlation plot

```{r}
corr_dat = covid_dat[rowTrain,] %>% 
  dplyr::select('age', 'height', 'weight', 'bmi', 'SBP', 'LDL')
corrplot(cor(corr_dat), method = "circle", type = "full")
```

## 1.2 Feature plot

```{r}
vis_trdat = trainData %>% 
  dplyr::select('age', 'height', 'weight', 'bmi', 'SBP', 'LDL', 'recovery_time')

theme1 = transparentTheme(trans = .4)
trellis.par.set(theme1)

featurePlot(x = vis_trdat[, 1:6],
            y = vis_trdat[, 7],
            scales = list(x = list(relation = "free"),
                          y = list(relation = "free")),
            plot = "box", pch = "|",
            auto.key = list(columns = 2))
```


# 2. Model training

## 2.1 GLM

```{r}
set.seed(2)
model.glm <- train(x = covid_dat2[rowTrain,],
                   y = covid_dat$recovery_time[rowTrain],
                   method = "glm",
                   trControl = ctrl)
```

## 2.2 Penalized logistic regression

```{r}
glmnGrid <- expand.grid(.alpha = seq(0, 1, length = 21),
                        .lambda = exp(seq(-8, -1, length = 50)))
set.seed(2)
model.glmn <- train(x = covid_dat2[rowTrain,],
                   y = covid_dat$recovery_time[rowTrain],
                    method = "glmnet",
                    tuneGrid = glmnGrid,
                    trControl = ctrl)

myCol<- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
              superpose.line = list(col = myCol))

plot(model.glmn, par.settings = myPar, xTrans = function(x) log(x))
```

## 2.3 GAM

```{r}
set.seed(2)
model.gam <- train(x = covid_dat2[rowTrain,],
                   y = covid_dat$recovery_time[rowTrain],
                   method = "gam",
                   trControl = ctrl)
```


## 2.4 MARS

```{r}
set.seed(2)
model.mars <- train(x = covid_dat2[rowTrain,],
                   y = covid_dat$recovery_time[rowTrain],
                    method = "earth",
                    tuneGrid = expand.grid(degree = 1:4, 
                                           nprune = 2:20),
                    trControl = ctrl)

plot(model.mars)
vip(model.mars$finalModel)
```

## 2.5 LDA

```{r,warning=FALSE}
set.seed(2)

model.lda <- train(x = covid_dat2[rowTrain,],
                   y = covid_dat$recovery_time[rowTrain],
                   method = "lda",
                   trControl = ctrl)
```

## 2.6 QDA

```{r,warning=FALSE}
set.seed(2)
model.qda <- train(x = covid_dat2[rowTrain,],
                   y = covid_dat$recovery_time[rowTrain],
                   method = "qda",
                   trControl = ctrl)
```

## 2.7 Naive Bayes (NB)

```{r, warning=FALSE,warning=FALSE}
nbGrid <- expand.grid(usekernel = c(FALSE,TRUE),
                      fL = 1, 
                      adjust = seq(.2, 3, by = .2))

set.seed(2)
model.nb <- train(x = covid_dat2[rowTrain,],
                  y = covid_dat$recovery_time[rowTrain],
                  method = "nb",
                  tuneGrid = nbGrid,
                  trControl = ctrl)

plot(model.nb)
```

## 2.8 classification tree models

### 2.8.1 classification tree-rpart

```{r,warning=FALSE}
num_cores <- detectCores() 
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)
set.seed(2)

model.rpart = train(recovery_time ~ .,
                    covid_dat,
                    subset = rowTrain,
                    method = "rpart",
                    tuneGrid = data.frame(cp = exp(seq(-6, -3, len = 50))),
                    trControl = ctrl)

ggplot(model.rpart, highlight = TRUE)

rpart.plot(model.rpart$finalModel)
stopCluster(cl)
registerDoSEQ()
```

### 2.8.2 classification ctree-ctree

```{r,warning=FALSE}
num_cores <- detectCores() 
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)

set.seed(2)


model.ctree = train(recovery_time ~ .,
                    covid_dat,
                    subset = rowTrain,
                    method = "ctree",
                    tuneGrid = data.frame(mincriterion = 1 - exp(seq(-2, -1, length = 50))),
                    trControl = ctrl)

ggplot(model.ctree, highlight = TRUE)

plot(model.ctree$finalModel)
stopCluster(cl)
registerDoSEQ()
```

## 2.9 Random forests

```{r}
num_cores <- detectCores() 
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)

rf.grid = expand.grid(mtry = 0:8,
                      splitrule = "gini",
                      min.node.size = seq(from = 2, to = 10, by = 2))
set.seed(2)
rf.fit = train(recovery_time ~ .,
               covid_dat,
               subset = rowTrain,
               method = "ranger",
               tuneGrid = rf.grid,
               trControl = ctrl)
ggplot(rf.fit, highlight = TRUE)

plot(model.ctree$finalModel)
stopCluster(cl)
registerDoSEQ()
```

## 2.10 Boosting

```{r}
num_cores <- detectCores() 
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)

gbmA_grid = expand.grid(n.trees = c(100, 250, 500, 1000, 2000, 3000),
                       interaction.depth = 1:6,
                       shrinkage = c(0.002, 0.005, 0.008),
                       n.minobsinnode = 1)
set.seed(2)
gbmA.fit = train(recovery_time ~ . ,
                covid_dat[rowTrain,],
                tuneGrid = gbmA_grid,
                trControl = ctrl,
                method = "gbm",
                distribution = "adaboost",
                verbose = FALSE)

gbmA.fit$bestTune
ggplot(gbmA.fit, highlight = TRUE)

stopCluster(cl)
registerDoSEQ()
```

## 2.11 Support Vector Machines

### 2.11.1 Support Vecotor Machines Linear

```{r,warning=FALSE}
num_cores <- detectCores() 
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)
set.seed(2)

model.svml <- train(recovery_time ~ .,
                  data = covid_dat[rowTrain, ],
                  method = "svmLinear2",
                  preProcess = c("center", "scale"),
                  tuneGrid = data.frame(cost = exp(seq(-3,2,len = 50))),
                  trControl = ctrl)

plot(model.svml, highlight = TRUE)

model.svml$bestTune
model.svml$finalModel

stopCluster(cl)
registerDoSEQ()
```


### 2.11.2 Support Vecotor Machines Radial Kernal

```{r,warning=FALSE}
num_cores <- detectCores() 
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)
svmr.grid <- expand.grid(C = exp(seq(-4,4,len=20)),
                         sigma = exp(seq(-4,0,len=10)))
#radial kernel
set.seed(2)

model.svmr <- train(recovery_time ~ .,
                  data = covid_dat[rowTrain, ],
                  method = "svmRadialSigma",
                  preProcess = c("center", "scale"),
                  tuneGrid = svmr.grid,
                  trControl = ctrl)

myCol<- rainbow(20)
myPar <- list(superpose.symbol = list(col = myCol),
              superpose.line = list(col = myCol))
ggplot(model.svmr, highlight = TRUE, par.settings = myPar)
```


# 3. Model Selection

## 3.1 Model Comparison

```{r resample, cache=TRUE,warning=FALSE}
res <- resamples(list(GLM = model.glm, 
                      GLMNET = model.glmn, 
                      GAM = model.gam, 
                      MARS = model.mars, 
                      CTREE = model.ctree, 
                      RPART = model.rpart, 
                      LDA = model.lda, 
                      QDA = model.qda, 
                      NB = model.nb,
                      SVML=model.svml,
                      SVMR=model.svmr, 
                      rf = rf.fit, 
                      boost = gbmA.fit))

summary(res)
bwplot(res)

```


## 3.2 Final Model- GAM

```{r}
# summary
model.gam$finalModel
model.gam$bestTune
summary(model.gam)

# visualization
ggplot(model.gam) +
  labs(tital = "GAM Classification") +
  theme_bw()

plot(model.gam)
par(mfrow = c(2,3))
plot(model.gam$finalModel)
par(mfrow = c(1,1))


# training error
pred.gam.train = predict(model.gam, newdata = covid_dat2[rowTrain,])
confusionMatrix(data = pred.gam.train, reference = covid_dat$recovery_time[rowTrain])

# test error
pred.gam.test = predict(model.gam, newdata = covid_dat2[-rowTrain,])
confusionMatrix(data = pred.gam.test, reference = covid_dat$recovery_time[-rowTrain])

```


